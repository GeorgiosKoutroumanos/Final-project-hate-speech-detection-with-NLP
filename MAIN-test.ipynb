{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f9bf24-c1e4-492f-9035-826879345ad2",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Import Libraries</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4a6660-b2d4-4296-b06a-0c4dde31cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "821263c4-6d7b-4077-896e-276b851ca34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0449957f-4302-45db-a226-9af70b101ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cf4d9-6afc-49f3-8017-5ca8fbee7924",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Import Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6156e0a-dc3c-4765-b995-bc5115bb5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\User\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\Dataset-Hate-Speech-Detection.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c61befe-d0a7-457d-91fe-ce94ea91e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c36b4cb8-9ce9-4154-93b8-dd977761c28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class                                              tweet\n",
       "0          2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1          1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2          1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3          1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4          1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
       "...      ...                                                ...\n",
       "24778      1  you's a muthaf***in lie &#8220;@LifeAsKing: @2...\n",
       "24779      2  you've gone and broke the wrong heart baby, an...\n",
       "24780      1  young buck wanna eat!!.. dat nigguh like I ain...\n",
       "24781      1              youu got wild bitches tellin you lies\n",
       "24782      2  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...\n",
       "\n",
       "[24783 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c46fc-5f6a-41a7-9cc9-5d05bf4eed76",
   "metadata": {},
   "source": [
    "Classification:\n",
    "\n",
    "- 0 - Hate Speech\n",
    "- 1 - Offensive Language\n",
    "- 2 - Neither/Neutral content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95050622-c7b3-4198-97e5-36c9ff297578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4687ac9f-6fe5-4241-9765-7257a7040668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.index = df.index + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a59cc695-faa8-494f-8dc4-432a33338660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet\n",
       "0      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb469788-7726-4421-b0d3-6461c489f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   class   24783 non-null  int64 \n",
      " 1   tweet   24783 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 387.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57c2ed28-1355-4eb5-afba-6210f5d3377d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e707e5-7246-4f87-9d35-eaee117bf4d2",
   "metadata": {},
   "source": [
    "NOTE: no null values & consistent datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf2a04-118a-4e3b-b529-99154aab6f71",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Cleaning tweet column</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8551278f-006d-43e6-baff-bda55b467589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a3e1f79-f5c3-4474-8928-38d8ebacd761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &amp;#128514;&amp;#128514;&amp;#128514;\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!&amp;#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&amp;#8221;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>\" &amp;amp; you might not get ya bitch back &amp;amp; thats that \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>\" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "5      1   \n",
       "6      1   \n",
       "7      1   \n",
       "8      1   \n",
       "9      1   \n",
       "\n",
       "                                                                                                                                                            tweet  \n",
       "0                    !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...  \n",
       "1                                                                           !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!  \n",
       "2                                        !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit  \n",
       "3                                                                                                  !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny  \n",
       "4                       !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;  \n",
       "5  !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"  \n",
       "6                                                       !!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"  \n",
       "7                                                              !!!!&#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&#8221;  \n",
       "8                                                                                                      \" &amp; you might not get ya bitch back &amp; thats that \"  \n",
       "9                                                                                                       \" @rhythmixx_ :hobbies include: fighting Mariam\"\\n\\nbitch  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[:10, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c89510e-ac72-40ef-b47c-c1e56f3646a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy11 queer\" gaywad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@CB_Baby24: @white_thunduh alsarabsss\" hes a beaner smh you can tell hes a mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@DevilGrimz: @VigxRArts you're fucking gay, blacklisted hoe\" Holding out for #TehGodClan anyway http://t.co/xUCcwoetmn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPLE https://t.co/RNvD2nLCDR\" This is why there's black people and niggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@NoChillPaz: \"At least I'm not a nigger\" http://t.co/RGJa7CfoiT\"\\n\\nLmfao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24576</th>\n",
       "      <td>0</td>\n",
       "      <td>this guy is the biggest faggot omfg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24685</th>\n",
       "      <td>0</td>\n",
       "      <td>which one of these names is more offensive kike, wop, kraut, wetback jigaboo, towelhead, gook, or redskin.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24751</th>\n",
       "      <td>0</td>\n",
       "      <td>you a pussy ass nigga and I know it nigga.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24776</th>\n",
       "      <td>0</td>\n",
       "      <td>you're all niggers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24777</th>\n",
       "      <td>0</td>\n",
       "      <td>you're such a retard i hope you get type 2 diabetes and die from a sugar rush you fucking faggot @Dare_ILK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1430 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "85         0   \n",
       "89         0   \n",
       "110        0   \n",
       "184        0   \n",
       "202        0   \n",
       "...      ...   \n",
       "24576      0   \n",
       "24685      0   \n",
       "24751      0   \n",
       "24776      0   \n",
       "24777      0   \n",
       "\n",
       "                                                                                                                         tweet  \n",
       "85                                                               \"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy11 queer\" gaywad  \n",
       "89                                         \"@CB_Baby24: @white_thunduh alsarabsss\" hes a beaner smh you can tell hes a mexican  \n",
       "110    \"@DevilGrimz: @VigxRArts you're fucking gay, blacklisted hoe\" Holding out for #TehGodClan anyway http://t.co/xUCcwoetmn  \n",
       "184      \"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPLE https://t.co/RNvD2nLCDR\" This is why there's black people and niggers  \n",
       "202                                                 \"@NoChillPaz: \"At least I'm not a nigger\" http://t.co/RGJa7CfoiT\"\\n\\nLmfao  \n",
       "...                                                                                                                        ...  \n",
       "24576                                                                                      this guy is the biggest faggot omfg  \n",
       "24685               which one of these names is more offensive kike, wop, kraut, wetback jigaboo, towelhead, gook, or redskin.  \n",
       "24751                                                                               you a pussy ass nigga and I know it nigga.  \n",
       "24776                                                                                                       you're all niggers  \n",
       "24777               you're such a retard i hope you get type 2 diabetes and die from a sugar rush you fucking faggot @Dare_ILK  \n",
       "\n",
       "[1430 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aefcacef-d10e-489a-8344-41393a69cfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet\n",
       "class       \n",
       "0       1430\n",
       "1      19190\n",
       "2       4163"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0dea078-2c15-4c82-ae5c-971b8dd315ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_count = df['class'].value_counts()\n",
    "\n",
    "ax = class_count.plot(kind='bar')\n",
    "\n",
    "for i, value in enumerate(class_count):\n",
    "    ax.text(i, value + 0.5, str(value), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40784d43-0db1-4df6-a439-aa24cc51470d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      2   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      1   \n",
       "\n",
       "                                                                                                                                          tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...  \n",
       "1                                                         !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!  \n",
       "2                      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit  \n",
       "3                                                                                !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny  \n",
       "4     !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[:5, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81b547d5-788f-43a5-9aff-a2bdebfde5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4a7166f-3f75-4059-9244-ceec29ed7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edit_distance_dictionary = 2\n",
    "prefix_length = 7\n",
    "sym_spell = SymSpell(max_edit_distance_dictionary, prefix_length)\n",
    "\n",
    "dictionary_path = \"frequency_dictionary_en_82_765.txt\"  # path to the downloaded dictionary\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = string.punctuation\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "def correct_spelling_symspell(text):\n",
    "    corrected_words = []\n",
    "    for word in text.split():\n",
    "        # Skip short words and stopwords to speed up\n",
    "        if len(word) < 3 or word in stop_words:\n",
    "            corrected_words.append(word)\n",
    "            continue\n",
    "        \n",
    "        suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "        if suggestions:\n",
    "            corrected_words.append(suggestions[0].term)\n",
    "        else:\n",
    "            corrected_words.append(word)\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = p.clean(text)\n",
    "    text = correct_spelling_symspell(text)\n",
    "    pattern = r'([{}])\\1+'.format(re.escape(punctuation))\n",
    "    text = re.sub(pattern, r'\\1', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    words = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df['tweet_cleaned'] = df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e17603a-3f46-4ee3-8722-73d20b074b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_cleaned'] = df['tweet_cleaned'].str.replace(r'!\\s*rt\\s*:', '', regex=True).str.replace(r\"[^\\w\\s.,!?']\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b4e40bc-6ba6-4ba3-a4b1-21dae6c669ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp;amp; as a man you should always take the trash out...</td>\n",
       "      <td>woman complain cleaning house camp man always take trash .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!</td>\n",
       "      <td>boy date cold.tyga bad coffin dat hoe st place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit</td>\n",
       "      <td>! rt dawg  ever fuck bitch start cry confused shit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny</td>\n",
       "      <td>look like granny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &amp;#57361;</td>\n",
       "      <td>shit hear might true might faker bitch told ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24778</th>\n",
       "      <td>1</td>\n",
       "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @20_Pearls @corey_emanuel right! His TL is trash &amp;#8230;. Now, mine? Bible scriptures and hymns&amp;#8221;</td>\n",
       "      <td>muthaf  lie   rights tl trash  . mine bible scriptures hymns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24779</th>\n",
       "      <td>2</td>\n",
       "      <td>you've gone and broke the wrong heart baby, and drove me redneck crazy</td>\n",
       "      <td>gone broke wrong heart baby drove redneck crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24780</th>\n",
       "      <td>1</td>\n",
       "      <td>young buck wanna eat!!.. dat nigguh like I aint fuckin dis up again</td>\n",
       "      <td>young buck wanna eat ! . dat nigga like int fucking dis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24781</th>\n",
       "      <td>1</td>\n",
       "      <td>youu got wild bitches tellin you lies</td>\n",
       "      <td>got wild bitches telling lies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24782</th>\n",
       "      <td>2</td>\n",
       "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful color combination of pink, orange, yellow &amp;amp; white. A Coll http://t.co/H0dYEBvnZB</td>\n",
       "      <td>ruffled  tax eileen dahlia  beautiful color combination pink orange yellow camp white roll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24783 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  \\\n",
       "0          2   \n",
       "1          1   \n",
       "2          1   \n",
       "3          1   \n",
       "4          1   \n",
       "...      ...   \n",
       "24778      1   \n",
       "24779      2   \n",
       "24780      1   \n",
       "24781      1   \n",
       "24782      2   \n",
       "\n",
       "                                                                                                                                                    tweet  \\\n",
       "0            !!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...   \n",
       "1                                                                   !!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!   \n",
       "2                                !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit   \n",
       "3                                                                                          !!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny   \n",
       "4               !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;   \n",
       "...                                                                                                                                                   ...   \n",
       "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @20_Pearls @corey_emanuel right! His TL is trash &#8230;. Now, mine? Bible scriptures and hymns&#8221;   \n",
       "24779                                                                              you've gone and broke the wrong heart baby, and drove me redneck crazy   \n",
       "24780                                                                                 young buck wanna eat!!.. dat nigguh like I aint fuckin dis up again   \n",
       "24781                                                                                                               youu got wild bitches tellin you lies   \n",
       "24782                     ~~Ruffled | Ntac Eileen Dahlia - Beautiful color combination of pink, orange, yellow &amp; white. A Coll http://t.co/H0dYEBvnZB   \n",
       "\n",
       "                                                                                     tweet_cleaned  \n",
       "0                                       woman complain cleaning house camp man always take trash .  \n",
       "1                                                   boy date cold.tyga bad coffin dat hoe st place  \n",
       "2                                               ! rt dawg  ever fuck bitch start cry confused shit  \n",
       "3                                                                                 look like granny  \n",
       "4                                                  shit hear might true might faker bitch told ya   \n",
       "...                                                                                            ...  \n",
       "24778                                muthaf  lie   rights tl trash  . mine bible scriptures hymns   \n",
       "24779                                              gone broke wrong heart baby drove redneck crazy  \n",
       "24780                                      young buck wanna eat ! . dat nigga like int fucking dis  \n",
       "24781                                                                got wild bitches telling lies  \n",
       "24782   ruffled  tax eileen dahlia  beautiful color combination pink orange yellow camp white roll  \n",
       "\n",
       "[24783 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ae744-403d-43cf-8bb9-c357c41b3fe4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc8b1218-0c9c-4ce2-b52e-e83901a492a3",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Model bulding</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0521d8-c321-4b81-ab42-d3573b5deee5",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">1 - Handling Imbalanced Data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "72112fb5-8d17-4210-904d-5d92ea98a9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1430</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19190</td>\n",
       "      <td>18728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4163</td>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet  tweet_cleaned\n",
       "class                      \n",
       "0       1430           1389\n",
       "1      19190          18728\n",
       "2       4163           4090"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f45e1e34-a8e4-47bf-a33f-801a5f366bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('tweet', inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0aa79405-7352-46e0-ac0e-beb5cdce905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='tweet_cleaned', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6d981138-10c3-48b0-b2d6-5db8492a25fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: class, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "multi_class_tweets = df.groupby('tweet_cleaned')['class'].nunique()\n",
    "\n",
    "tweets_with_multiple_classes = multi_class_tweets[multi_class_tweets > 1]\n",
    "\n",
    "print(tweets_with_multiple_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4c87c072-7b94-4a8d-8f5a-41be14aa05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['class'] == 0]   # All hate speech tweets\n",
    "df_1 = df[df['class'] == 1]   # All offensive tweets\n",
    "df_2 = df[df['class'] == 2]   # All neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aba22e6-c236-4142-ab79-f3e6d0bb7535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18718"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_size = df_1.shape[0]\n",
    "max_size \n",
    "\n",
    "#there are duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "11c17208-2824-44d9-b47d-120e0bd1725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_cleaned\n",
       "class               \n",
       "0               1375\n",
       "1              18718\n",
       "2               4084"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('class').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae24ff7e-d309-483e-acce-ca2770a10359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_upsampled = resample(df_0, replace=True, n_samples=max_size, random_state=42)\n",
    "df_2_upsampled = resample(df_2, replace=True, n_samples=max_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3d0b8c4-6d1c-497c-bc0c-8635da8b5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_0_upsampled, df_2_upsampled, df_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ee01deb8-8f20-49ed-99cc-d2fdb0fe4292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_cleaned\n",
       "class               \n",
       "0              18718\n",
       "1              18718\n",
       "2              18718"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6b3aabe1-4487-4ffc-8fc5-64b30ce1e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0140a214-a22b-4a19-87c0-3449195d739f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_cleaned\n",
       "class               \n",
       "0              18718\n",
       "1              18718\n",
       "2              18718"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "cfb90550-8f34-44a2-af20-f959f9467d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet_cleaned</th>\n",
       "      <th>char_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>lied hurt like bitch bruises army would suggest low</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>french word potato translates earth apple banana long yellow tree apple submarines big wet hollow kaboom apple</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  \\\n",
       "0      1   \n",
       "1      2   \n",
       "\n",
       "                                                                                                    tweet_cleaned  \\\n",
       "0                                                             lied hurt like bitch bruises army would suggest low   \n",
       "1  french word potato translates earth apple banana long yellow tree apple submarines big wet hollow kaboom apple   \n",
       "\n",
       "   char_length  \n",
       "0           51  \n",
       "1          110  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "88fc55b8-d194-4f3c-9cfa-8f85e7d68e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    56154.000000\n",
      "mean        49.102913\n",
      "std         25.213088\n",
      "min          0.000000\n",
      "25%         28.000000\n",
      "50%         46.000000\n",
      "75%         68.000000\n",
      "max        146.000000\n",
      "Name: char_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_balanced[\"char_length\"] = df_balanced[\"tweet_cleaned\"].apply(len)\n",
    "print(df_balanced[\"char_length\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fd82c-8582-46cd-b5fe-21a4a68805b6",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">2 - RoBERTa model bulding</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e78743-2e91-41e3-bb4c-f17e36c704a1",
   "metadata": {},
   "source": [
    "Using a lighter version or Roberta, distilroberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6ee99492-6d6c-4979-b6e6-9ca7f25ba0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_16328\\230380063.py:1: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_reduced = df_balanced.groupby('class', group_keys=False).apply(lambda x: x.sample(frac=0.7, random_state=42)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df_reduced = df_balanced.groupby('class', group_keys=False).apply(lambda x: x.sample(frac=0.7, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "4b26db3e-ecf4-41a2-b193-2c150235f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = df_reduced.drop(columns=['char_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9aa7b38d-5af2-474e-8115-2337bb2eff32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_cleaned</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_cleaned\n",
       "class               \n",
       "0              13103\n",
       "1              13103\n",
       "2              13103"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "dec5167f-820d-4d1d-8a25-41832f5887e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reduced[\"tweet_cleaned\"]\n",
    "y = df_reduced[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "91b60dce-967b-48e1-8130-6885b5e2d37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "5cb08d1c-8412-4f50-ac08-6c4f04fcab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0318a4d3-2d14-45e5-9447-442f874ce3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True, max_length=150) # changed the length (actuals length 147)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True, max_length=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "cce98955-abce-4b89-ad17-77109803d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "24721660-b26a-4bb0-a2d4-35a4ce23f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx])\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TweetDataset(train_encodings, y_train)\n",
    "test_dataset = TweetDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "281abbde-3431-4fbd-be4b-38ba132e5663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"distilroberta-base\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "100371df-2506-494b-8767-d93bd70acbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\training_args.py:1577: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=20,\n",
    "    per_device_eval_batch_size=20,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1000,\n",
    "    no_cuda=True  # to force CPU usage if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "7d283374-6c71-4bf6-809c-30286cc32e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8a342299-f44c-40e3-afd0-17f1fd0dff48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='81' max='1573' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  81/1573 07:37 < 2:23:54, 0.17 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[239]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2238\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2239\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2241\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2242\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2245\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\trainer.py:2555\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2548\u001b[39m context = (\n\u001b[32m   2549\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2550\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2551\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2552\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2553\u001b[39m )\n\u001b[32m   2554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2555\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2558\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2559\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2560\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2561\u001b[39m ):\n\u001b[32m   2562\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2563\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\trainer.py:3745\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(self, model, inputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb.reduce_mean().detach().to(\u001b[38;5;28mself\u001b[39m.args.device)\n\u001b[32m   3744\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compute_loss_context_manager():\n\u001b[32m-> \u001b[39m\u001b[32m3745\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3747\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[32m   3748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   3749\u001b[39m     \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3750\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.global_step % \u001b[38;5;28mself\u001b[39m.args.torch_empty_cache_steps == \u001b[32m0\u001b[39m\n\u001b[32m   3751\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\trainer.py:3810\u001b[39m, in \u001b[36mTrainer.compute_loss\u001b[39m\u001b[34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[39m\n\u001b[32m   3808\u001b[39m         loss_kwargs[\u001b[33m\"\u001b[39m\u001b[33mnum_items_in_batch\u001b[39m\u001b[33m\"\u001b[39m] = num_items_in_batch\n\u001b[32m   3809\u001b[39m     inputs = {**inputs, **loss_kwargs}\n\u001b[32m-> \u001b[39m\u001b[32m3810\u001b[39m outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3811\u001b[39m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[32m   3812\u001b[39m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.past_index >= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1202\u001b[39m, in \u001b[36mRobertaForSequenceClassification.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1185\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1186\u001b[39m \u001b[33;03mtoken_type_ids (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m   1187\u001b[39m \u001b[33;03m    Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,1]`:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1198\u001b[39m \u001b[33;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[32m   1199\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1200\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m-> \u001b[39m\u001b[32m1202\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1213\u001b[39m sequence_output = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1214\u001b[39m logits = \u001b[38;5;28mself\u001b[39m.classifier(sequence_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:869\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    862\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    863\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    864\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    865\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    866\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    867\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    882\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:618\u001b[39m, in \u001b[36mRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    607\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    608\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    609\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    615\u001b[39m         output_attentions,\n\u001b[32m    616\u001b[39m     )\n\u001b[32m    617\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m618\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    619\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    621\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    623\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    625\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    628\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:549\u001b[39m, in \u001b[36mRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    546\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    547\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    552\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    554\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\pytorch_utils.py:253\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:562\u001b[39m, in \u001b[36mRobertaLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    560\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m    561\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m     layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:474\u001b[39m, in \u001b[36mRobertaOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m    473\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dense(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n\u001b[32m    476\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\modules\\dropout.py:70\u001b[39m, in \u001b[36mDropout.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\myfinalproject\\Lib\\site-packages\\torch\\nn\\functional.py:1425\u001b[39m, in \u001b[36mdropout\u001b[39m\u001b[34m(input, p, training, inplace)\u001b[39m\n\u001b[32m   1422\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p < \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p > \u001b[32m1.0\u001b[39m:\n\u001b[32m   1423\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m-> \u001b[39m\u001b[32m1425\u001b[39m     _VF.dropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1426\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57db2abb-3e82-4f4d-a580-29484ca23614",
   "metadata": {},
   "source": [
    "[ 46/8424 06:22 < 20:14:03, 0.12 it/s, Epoch 0.02/3] with Roberta\n",
    "\n",
    "[ 28/2247 02:28 < 3:31:28, 0.17 it/s, Epoch 0.01/1] with distilroberta-base\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=20,\n",
    "    per_device_eval_batch_size=20,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1000\n",
    ")\n",
    "\n",
    "[ 4/2247 00:08 < 2:32:10, 0.25 it/s, Epoch 0.00/1] with distilroberta-base -> the best results\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=20,\n",
    "    per_device_eval_batch_size=20,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1000,\n",
    ")\n",
    "\n",
    "[ 38/2247 02:42 < 2:45:43, 0.22 it/s, Epoch 0.02/1] with j-hartmann/emotion-english-distilroberta-base -> no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea370ae-cfae-4ea1-a06c-3019c46d534f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d6959-03da-4b88-94fa-2f6c6241da86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff3180-7408-4451-9586-1688ac1c958f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b03dd2df-6ec9-4331-b6c9-c23a523d9197",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">2 - BERT model bulding</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myfinalproject)",
   "language": "python",
   "name": "myfinalproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
