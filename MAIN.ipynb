{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5f9bf24-c1e4-492f-9035-826879345ad2",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Import Libraries</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6e2c3-4a02-4d39-8fcc-4f4462ac51a9",
   "metadata": {},
   "source": [
    "!pip install tweet-preprocessor\n",
    "!pip install pyspellchecker\n",
    "!pip install symspellpy\n",
    "!pip install transformers datasets\n",
    "!pip install torch torchvision torchaudio --quiet\n",
    "!pip install transformers datasets --quiet\n",
    "!pip install -U accelerate\n",
    "!pip install --upgrade pip\n",
    "!pip install evaluate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e25573-ca66-4270-af27-de2bf1fe93c5",
   "metadata": {},
   "source": [
    "!pip install hf_xet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a345a-9e27-4d5d-be40-ec6b4690e44a",
   "metadata": {},
   "source": [
    "!pip install --upgrade transformers --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976bd75-414c-473c-bcb1-c0aaf0a81bcc",
   "metadata": {},
   "source": [
    "!pip install numpy==1.26.4 --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e8342-bdca-49f0-ac4b-990b870d4aeb",
   "metadata": {},
   "source": [
    "!python -m pip install ipykernel\n",
    "!python -m ipykernel install --user --name transformers452 --display-name \"Python (Transformers 4.52)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d8910be-3516-407d-a2d2-d6f45516ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.26.4\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.0\n",
      "    Uninstalling numpy-2.3.0:\n",
      "      Successfully uninstalled numpy-2.3.0\n",
      "Successfully installed numpy-1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\anaconda3\\Lib\\site-packages\\~.mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\User\\anaconda3\\Lib\\site-packages\\~.mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "streamlit 1.37.1 requires packaging<25,>=20, but you have packaging 25.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.26.4 --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dbeb605-56cc-4b1d-b2af-b55dc3666ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\windows_events.py\", line 322, in run_forever\n",
      "    super().run_forever()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_10916\\1521273946.py\", line 2, in <module>\n",
      "    import matplotlib.pyplot as plt\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 159, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 28, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 57, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 144, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\User\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\_multiarray_umath.py:46\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr_name)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[0;32m     45\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     48\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.0 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "initialization failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:159\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BackendFilter, backend_registry\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py:144\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 144\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    146\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    148\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    149\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    157\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: initialization failed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeabf15d-cf21-4578-b116-d527bbe91562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821263c4-6d7b-4077-896e-276b851ca34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import preprocessor as p\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from spellchecker import SpellChecker\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449957f-4302-45db-a226-9af70b101ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cf4d9-6afc-49f3-8017-5ca8fbee7924",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Import Dataset</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6156e0a-dc3c-4765-b995-bc5115bb5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\User\\Desktop\\Ironhack_DA\\Final-project-hate-speech-detection-with-NLP\\Dataset-Hate-Speech-Detection.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61befe-d0a7-457d-91fe-ce94ea91e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36b4cb8-9ce9-4154-93b8-dd977761c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7c46fc-5f6a-41a7-9cc9-5d05bf4eed76",
   "metadata": {},
   "source": [
    "Class explanation:\n",
    "\n",
    "- 0 - Hate Speech\n",
    "- 1 - Offensive Language\n",
    "- 2 - Neither/Neutral content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95050622-c7b3-4198-97e5-36c9ff297578",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4687ac9f-6fe5-4241-9765-7257a7040668",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.index = df.index + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59cc695-faa8-494f-8dc4-432a33338660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb469788-7726-4421-b0d3-6461c489f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c2ed28-1355-4eb5-afba-6210f5d3377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e707e5-7246-4f87-9d35-eaee117bf4d2",
   "metadata": {},
   "source": [
    "NOTE: no null values & consistent datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcf2a04-118a-4e3b-b529-99154aab6f71",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Cleaning tweet column</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8551278f-006d-43e6-baff-bda55b467589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e1f79-f5c3-4474-8928-38d8ebacd761",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.iloc[:10, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c89510e-ac72-40ef-b47c-c1e56f3646a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['class'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcacef-d10e-489a-8344-41393a69cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dea078-2c15-4c82-ae5c-971b8dd315ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = df['class'].value_counts()\n",
    "\n",
    "ax = class_count.plot(kind='bar')\n",
    "\n",
    "for i, value in enumerate(class_count):\n",
    "    ax.text(i, value + 0.5, str(value), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40784d43-0db1-4df6-a439-aa24cc51470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.iloc[:5, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b547d5-788f-43a5-9aff-a2bdebfde5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef875e-242f-4f2d-a227-9545dc129ba7",
   "metadata": {},
   "source": [
    "df['tweet'].lower() #lower case\n",
    "punc_to_remove = string.punctuations\n",
    "df['tweet'].translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\" \".join(df['tweet'].split())\n",
    "contractions.fix(df['tweet'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0495ee-f9a3-4e8f-b65a-6a1c7a95f612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.tweet.str.lower(inplace = True)\n",
    "\n",
    "#df['tweet'].replace(string.punctuation,'')\n",
    "\n",
    "#def cleaned_tweet(text):\n",
    "    # Remove punctuation\n",
    "    #text = ''.join(char for char in text if char not in string.punctuation)\n",
    "    #return text.lower()  # Optional: lowercasing\n",
    "\n",
    "# Apply the cleaning function to the 'tweet' column\n",
    "#df['tweet'] = df['tweet'].apply(cleaned_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7166f-3f75-4059-9244-ceec29ed7515",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_edit_distance_dictionary = 2\n",
    "prefix_length = 7\n",
    "sym_spell = SymSpell(max_edit_distance_dictionary, prefix_length)\n",
    "\n",
    "dictionary_path = \"frequency_dictionary_en_82_765.txt\"  # path to the downloaded dictionary\n",
    "sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.EMOJI)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punctuation = string.punctuation\n",
    "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "def correct_spelling_symspell(text):\n",
    "    corrected_words = []\n",
    "    for word in text.split():\n",
    "        # Skip short words and stopwords to speed up\n",
    "        if len(word) < 3 or word in stop_words:\n",
    "            corrected_words.append(word)\n",
    "            continue\n",
    "        \n",
    "        suggestions = sym_spell.lookup(word, Verbosity.CLOSEST, max_edit_distance=2)\n",
    "        if suggestions:\n",
    "            corrected_words.append(suggestions[0].term)\n",
    "        else:\n",
    "            corrected_words.append(word)\n",
    "    return \" \".join(corrected_words)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = p.clean(text)\n",
    "    text = correct_spelling_symspell(text)\n",
    "    pattern = r'([{}])\\1+'.format(re.escape(punctuation))\n",
    "    text = re.sub(pattern, r'\\1', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    words = [w for w in tokens if w not in stop_words]\n",
    "    return \" \".join(words)\n",
    "\n",
    "df['tweet_cleaned'] = df['tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17603a-3f46-4ee3-8722-73d20b074b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_cleaned'] = df['tweet_cleaned'].str.replace(r'!\\s*rt\\s*:', '', regex=True).str.replace(r\"[^\\w\\s.,!?']\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4e40bc-6ba6-4ba3-a4b1-21dae6c669ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b1218-0c9c-4ce2-b52e-e83901a492a3",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">Model bulding</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0521d8-c321-4b81-ab42-d3573b5deee5",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">1 - Handling Imbalanced Data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72112fb5-8d17-4210-904d-5d92ea98a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e1e34-a8e4-47bf-a33f-801a5f366bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('tweet', inplace = True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa79405-7352-46e0-ac0e-beb5cdce905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='tweet_cleaned', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d981138-10c3-48b0-b2d6-5db8492a25fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class_tweets = df.groupby('tweet_cleaned')['class'].nunique()\n",
    "\n",
    "tweets_with_multiple_classes = multi_class_tweets[multi_class_tweets > 1]\n",
    "\n",
    "print(tweets_with_multiple_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c87c072-7b94-4a8d-8f5a-41be14aa05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['class'] == 0]   # All hate speech tweets\n",
    "df_1 = df[df['class'] == 1]   # All offensive tweets\n",
    "df_2 = df[df['class'] == 2]   # All neutral tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba22e6-c236-4142-ab79-f3e6d0bb7535",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = df_1.shape[0]\n",
    "max_size \n",
    "\n",
    "#there are duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c17208-2824-44d9-b47d-120e0bd1725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('class').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24ff7e-d309-483e-acce-ca2770a10359",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_upsampled = resample(df_0, replace=True, n_samples=max_size, random_state=42)\n",
    "df_2_upsampled = resample(df_2, replace=True, n_samples=max_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0b8c4-6d1c-497c-bc0c-8635da8b5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = pd.concat([df_0_upsampled, df_2_upsampled, df_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01deb8-8f20-49ed-99cc-d2fdb0fe4292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.groupby('class').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3aabe1-4487-4ffc-8fc5-64b30ce1e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140a214-a22b-4a19-87c0-3449195d739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.groupby('class').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9fd82c-8582-46cd-b5fe-21a4a68805b6",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">2 - RoBERTa model bulding</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e78743-2e91-41e3-bb4c-f17e36c704a1",
   "metadata": {},
   "source": [
    "Using a lighter version or Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a92af63-358f-4e5c-85da-205d0c9d5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_balanced.rename(columns={\"tweet_cleaned\": \"text\", \"class\": \"label\"}) # a hugging face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc84fda-5965-4c72-9d2c-c1994d3c497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c814e7b-ef99-4ba5-8d36-716763709d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38d87c-9d8e-46ae-89fc-f7fae76a4786",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c4409-5d07-4dd7-b5fc-98aa5b23c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99cc0ec-9abb-4aa1-8d8e-f51099d62b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd8b91c-c4de-48e2-a982-cf08e412a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9792f4-b141-42e2-9ed4-d58908745bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilroberta-base\", num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3687f8-7680-4bec-8d8c-612c28c182ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,                    # Fast: just 1 epoch\n",
    "    per_device_train_batch_size=8,        # Small batch = faster on CPU\n",
    "    evaluation_strategy=\"epoch\",          # Evaluate every epoch\n",
    "    save_strategy=\"no\",                   # Skip saving after each epoch\n",
    "    logging_strategy=\"epoch\",             # Show logs each epoch\n",
    "    report_to=\"none\",                     # No external logging (e.g., WandB)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15c43e-8db8-4237-bac6-3ca829cbd373",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")  # Standard accuracy metric\n",
    "f1 = evaluate.load(\"f1\")              # F1 score — balances precision and recall\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred             # Raw model outputs and true labels\n",
    "    predictions = logits.argmax(axis=-1)  # Get predicted class by choosing max logit value\n",
    "    return {\n",
    "        \"accuracy\": accuracy.compute(predictions=predictions, references=labels),\n",
    "        \"f1\": f1.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0551f1c2-38c6-434e-9f5c-5801096b45c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # Our RoBERTa model\n",
    "    args=training_args,                  # Training configuration\n",
    "    train_dataset=tokenized_dataset[\"train\"],  # Training data\n",
    "    eval_dataset=tokenized_dataset[\"test\"],    # Evaluation data\n",
    "    tokenizer=tokenizer,                 # Tokenizer (helps with decoding & padding)\n",
    "    compute_metrics=compute_metrics     # Function to calculate metrics during evaluation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837642d-3107-4ef0-a8be-a7db6ece0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619bf29f-f1dc-47c8-9d93-28a946832fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea370ae-cfae-4ea1-a06c-3019c46d534f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d6959-03da-4b88-94fa-2f6c6241da86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff3180-7408-4451-9586-1688ac1c958f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b03dd2df-6ec9-4331-b6c9-c23a523d9197",
   "metadata": {},
   "source": [
    "##### <span style=\"color:#483D8B; font-weight:bold;\">2 - BERT model bulding</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Transformers 4.52)",
   "language": "python",
   "name": "transformers452"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
